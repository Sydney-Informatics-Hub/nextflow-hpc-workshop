# 1.4 HPC fundamentals - Parallelisation

## 1.4.1 Pros and cons of parallelisation

## 1.4.2 The scatter/gather pattern

!!! example "Exercise 1.4.2: Scatter/gather for genome alignment"

    Continuing with our theme of variant calling, in this exercise we will implement a basic scatter/gather pattern within the context of aligning reads to a genome.

    We have pre-loaded a couple of scripts for you in your working directory:

    - `align.<HPC_NAME>.sh`: This script runs the tool `bwa-mem` to align each read in a pair of FASTQ files to a position in a given genome.
    - `concat.<HPC_NAME>.sh`: This script takes multiple BAM files (generated by `bwa-mem`) and concatenates them together - i.e. it "pastes" them together into a single BAM file.

    We have also pre-loaded a reference genome that can be used with `bwa-mem`, in the folder `ref/BWAIndex/`.

    The goal of this exercise will be to write a script that takes a pair of FASTQ files and splits them into several chunks. Each chunk will then be run separately through the `align.sh` script. This will create a BAM file for each chunk. After they have finished, we can submit the `concat.sh` script to find 

    Start by creating a new empty file in the current directory called `split_fastq.sh`. You can do this via the VSCode interface by right-clicking on the current directory name and clicking "New File...", then typing in the name `split_fastq.sh` and pressing `Enter`.

    Open the file and start by adding the header comments:

    === "Gadi"

        ```bash title="split_fastq.sh"
        #!/bin/bash
        #PBS -P ab01
        #PBS -N split_fastq
        #PBS -q normalbw
        #PBS -l ncpus=1
        #PBS -l mem=1GB
        #PBS -l walltime=00:01:00
        #PBS -l storage=scratch/ab01
        #PBS -l wd
        ```

    === "Setonix"

        ```bash title="split_fastq.sh"
        #!/bin/bash
        #SBATCH --account=pawsey1234
        #SBATCH --job-name=split_fastq
        #SBATCH --partition=work
        #SBATCH --nodes=1
        #SBATCH --ntasks=1
        #SBATCH --cpus-per-task=1
        #SBATCH --mem=1GB
        #SBATCH --time=00:01:00
        ```

    **Note**: Be sure to substitute your project ID for the placeholder given in the example above.

    Next, let's define some bash variables to help reduce repetition in our script:

    ```bash title="split_fastq.sh (continued)"
    SAMPLE_ID="tiny"
    READS_1="data/${SAMPLE_ID}.R1.fq"
    READS_2="data/${SAMPLE_ID}.R2.fq"
    ```

    Now we're ready to split our FASTQ files up into chunks. In this example, we are working with a very tiny pair of FASTQ files with just 10 reads (40 lines per file). For simplicity, we will use the `split` command to break the FASTQs up into 4 pairs, with at most 12 lines (3 reads) per pair:

    ```bash title="split_fastq.sh (continued)"
    mkdir -p results/fastq_split
    split -l 12 -d --additional-suffix=".R1.fq" ${READS_1} results/fastq_split/${SAMPLE_ID}.split_
    split -l 12 -d --additional-suffix=".R2.fq" ${READS_2} results/fastq_split/${SAMPLE_ID}.split_
    ```

    Finally, we will use a useful feature of both Gadi and Setonix: we will submit the alignment jobs *from within* the `split_fastq.sh` job:

    === "Gadi"

        ```bash title="split_fastq.sh (continued)"
        for f in results/fastq_split/${SAMPLE_ID}.split_*.R1.fq
        do
            qsub -v SAMPLE_ID="${SAMPLE_ID}",READS_1="${f}",READS_2="${f:0:(-4)}2.fq" align.gadi.sh
        done
        ```

        Note that we are using a new `qsub` parameter: `-v`. This lets us set named environment variables within the script; in this case, we are setting the values of `${SAMPLE_ID}`, `${READS_1}` and `${READS_2}`.

    === "Setonix"

        ```bash title="split_fastq.sh (continued)"
        for f in results/fastq_split/${SAMPLE_ID}.split_*.R1.fq
        do
            sbatch --export SAMPLE_ID="${SAMPLE_ID}",READS_1="${f}",READS_2="${f:0:(-4)}2.fq" align.setonix.sh
        done
        ```

        Note that we are using a new `sbatch` parameter: `--export`. This lets us set named environment variables within the script; in this case, we are setting the values of `${SAMPLE_ID}`, `${READS_1}` and `${READS_2}`.

    The final script should like like the following:

    === "Gadi"

        ```bash title="split_fastq.sh (complete)"
        #!/bin/bash
        #PBS -P ab01
        #PBS -N split_fastq
        #PBS -q normalbw
        #PBS -l ncpus=1
        #PBS -l mem=1GB
        #PBS -l walltime=00:01:00
        #PBS -l storage=scratch/ab01
        #PBS -l wd

        SAMPLE_ID="tiny"
        READS_1="data/${SAMPLE_ID}.R1.fq"
        READS_2="data/${SAMPLE_ID}.R2.fq"

        mkdir -p results/fastq_split
        split -l 12 -d --additional-suffix=".R1.fq" ${READS_1} results/fastq_split/${SAMPLE_ID}.split_
        split -l 12 -d --additional-suffix=".R2.fq" ${READS_2} results/fastq_split/${SAMPLE_ID}.split_

        for f in results/fastq_split/${SAMPLE_ID}.split_*.R1.fq
        do
            qsub -v SAMPLE_ID="${SAMPLE_ID}",READS_1="${f}",READS_2="${f:0:(-4)}2.fq" align.gadi.sh
        done
        ```

    === "Setonix"

        ```bash title="split_fastq.sh (complete)"
        #!/bin/bash
        #SBATCH --account=pawsey1234
        #SBATCH --job-name=split_fastq
        #SBATCH --partition=work
        #SBATCH --nodes=1
        #SBATCH --ntasks=1
        #SBATCH --cpus-per-task=1
        #SBATCH --mem=1GB
        #SBATCH --time=00:01:00

        SAMPLE_ID="tiny"
        READS_1="data/${SAMPLE_ID}.R1.fq"
        READS_2="data/${SAMPLE_ID}.R2.fq"

        mkdir -p results/fastq_split
        split -l 12 -d --additional-suffix=".R1.fq" ${READS_1} results/fastq_split/${SAMPLE_ID}.split_
        split -l 12 -d --additional-suffix=".R2.fq" ${READS_2} results/fastq_split/${SAMPLE_ID}.split_

        for f in results/fastq_split/${SAMPLE_ID}.split_*.R1.fq
        do
            sbatch --export SAMPLE_ID="${SAMPLE_ID}",READS_1="${f}",READS_2="${f:0:(-4)}2.fq" align.setonix.sh
        done
        ```

    You can go ahead and submit this job. Once the FASTQs are split, the job will submit four new alignment jobs.

    === "Gadi"

        ```bash
        qsub split_fastq.sh
        ```

        You can monitor the job with the `qstat -u ${USER}` command.

    === "Setonix"

        ```bash
        sbatch split_fastq.sh
        ```

        You can monitor the job with the `squeue -u ${USER}` command.

    Once the jobs have completed successfully, you should have the following files under the `results` folder:

    ```bash
    tree results/
    ```

    ```console title="Output"
    results/
    ├── align_tiny
    │   ├── tiny.split_00.bam
    │   ├── tiny.split_01.bam
    │   ├── tiny.split_02.bam
    │   └── tiny.split_03.bam
    └── fastq_split
        ├── tiny.split_00.R1.fq
        ├── tiny.split_00.R2.fq
        ├── tiny.split_01.R1.fq
        ├── tiny.split_01.R2.fq
        ├── tiny.split_02.R1.fq
        ├── tiny.split_02.R2.fq
        ├── tiny.split_03.R1.fq
        └── tiny.split_03.R2.fq
    ```

    You have successfully split a FASTQ file into chunks and "scattered" what would have originally been a single alignment job into four smaller alignment jobs.

    Now, you can submit the `concat.<HPC_NAME>.sh` script to perform the "gather" stage by combining the results of the four alignment jobs back into a single alignment file:

    === "Gadi"

        ```bash
        qsub -v SAMPLE_ID="tiny" concat.gadi.sh
        ```

        Again, note that we are using the `-v` option here to set the `${SAMPLE_ID}` environment variable within the `concat.gadi.sh` script.

    === "Setonix"

        ```bash
        sbatch --export SAMPLE_ID="tiny" concat.setonix.sh
        ```

        Again, note that we are using the `--export` option here to set the `${SAMPLE_ID}` environment variable within the `concat.setonix.sh` script.

    Once complete, you will have a new BAM file located at `results/align_tiny/tiny.bam`. This file contains all of the reads that are present in the `tiny.split_*.bam` files.
